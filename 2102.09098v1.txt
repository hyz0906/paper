这篇论文主要描述了在Google开发的构建目标分批服务(Build Target Batching Service, BTBS)。

主要内容包括:

Google代码仓库巨大,每个代码变更会影响大量的构建目标(build targets)。为确保变更不破坏代码,需要构建和测试大量目标。但一次构建太多目标会导致内存不足错误或超时。
BTBS将大量目标分批,对每个批次生成构建,以避免内存不足或超时。它使用机器学习模型预测每个构建的内存和执行器使用,通过二分查找将目标分成符合限制的批次。
内存模型预测构建内存峰值。执行器模型预测构建的平均执行器占用。这两个模型都使用目标、参数等作为特征,通过回归预测资源使用。
评估显示BTBS能将内存不足错误率控制在0.08%,超时错误率控制在0.05%。大部分批次都是由内存或执行器模型生成。这表明模型对控制资源使用非常关键。
总体而言,BTBS通过智能分批有效解决了超大规模构建的资源限制问题,提高了开发效率。其设计思路对类似场景也具有借鉴意义。
Copy

请详细解析BTBS

YH
好的,我来详细解析一下BTBS的工作原理:

输入:BTBS通过流式RPC接口EnqueueTargets接收构建目标。第一个请求包含执行上下文、构建参数等,后续请求包含其他构建目标。
分组:根据目标的执行器类型将目标分组,同一组目标使用相同类型的执行器。这可以避免目标之间的相互影响。
排序:对每个组内的目标按路径字典序排序。这是为了增加相邻目标有相似依赖的概率,缩小构建依赖图,降低内存用量。
分批:对每个组执行分批算法,详见下文。
创建构建:对每个批次使用第一步的执行上下文和参数创建构建,加入构建服务执行队列。
失败重试:内存不足的构建将目标均分成两半重试,超时的构建直接重试,以利用缓存。
分批算法:

初始化批次列表。
当还有未批目标时,取前maxTargetsPerBatch个目标作为初始批次。
用内存模型对批次做二分查找,使内存使用低于阈值。
用执行器模型对上一步的批次继续二分查找,使执行器占用低于阈值。
将批次加入批次列表,从未批目标中移除该批次的目标。
返回批次列表。
内存和执行器模型都使用目标、参数等特征做回归预测。内存模型预测内存峰值,执行器模型预测平均执行器占用。这些模型的预测值用于二分查找阶段。

Copy

请输出论文的思维导图

YH
好的,这里是我根据该论文构建的思维导图:

mermaid

Copy code

graph TD
    A[Google代码库庞大]
    B[单次变更影响大量构建目标]
    C[一次构建太多目标容易OOM或超时]

    subgraph BTBS
    D[接收构建目标]
    E[分组目标]
    F[排序目标]
    G[分批目标]
    H[创建构建]
    I[失败重试]
    end

    J[内存模型]
    K[执行器模型]

    D-->E
    E-->F
    F-->G
    G-->H
    H-->I

    G-->J
    G-->K

    J-.预测内存使用.->G
    K-.预测执行器使用.->G
这张思维导图总结了论文的主要内容:

Google代码库非常大,每个代码变更会影响大量构建目标。
一次构建太多目标容易导致OOM错误或超时。
BTBS服务接收构建目标,进行分组、排序、分批,创建构建,并进行失败重试。
内存模型和执行器模型用于预测资源使用,以指导分批过程。
通过智能分批,BTBS解决了超大规模构建的资源限制问题。
主线是BTBS的工作流程,关键组件是内存模型和执行器模型。希望这个导图能直观表明论文的主要思路。

Copy

请逐段分析论文内容

YH
好的,我来逐段分析该论文的内容:

【摘要】

Google代码库包含数亿构建目标,需要频繁构建和测试部分目标。
构建服务系统使用Bazel构建目标。Bazel以构建文件为输入。
一次构建过多目标会导致内存不足或超时错误。
论文提出了构建目标分批技术,可以预测内存和执行器使用情况,将目标分批以避免错误。
结果显示技术可以将内存错误降低到0.08%,超时错误降低到0.05%。
【引言】

Google代码库庞大,每天10多万次代码提交,每个提交影响许多目标。
持续集成系统需要构建和测试受影响的目标,确保不破坏代码。
构建服务系统使用Bazel构建目标,以构建文件为输入。
一次构建过多目标会导致内存不足或超时错误,降低开发效率。
论文提出一种技术,可以预测内存和执行器使用情况,通过分批避免上述错误。
【背景】

介绍了Bazel的工作方式,以及关键的参数对构建的影响。
构建服务系统的架构,包含调度服务、执行集群等组件。
构建可能由于内存不足或执行器使用超限导致错误。
讲解了线性回归等机器学习方法。
【构建目标分批服务】

BTBS提供了流式RPC接口接收构建目标。
根据执行器类型分组目标,按路径排序,以缩小依赖图降低内存用量。
使用二分查找式的分批算法,用内存和执行器模型预测资源使用,将目标分到符合限制的批次中。
为每个批次创建构建加入执行队列。
失败构建会retry以重用缓存加速。
【模型预测】

收集构建的内存峰值、执行器使用等数据作为模型输入和标签。
使用互信息法等提取重要特征,交叉特征等扩充特征。
内存模型预测内存峰值,执行器模型预测平均执行器占用。
使用正则化保证内存模型单调性。
每天使用近期数据重新训练模型。
【评估】

BTBS在生产广泛使用,工作稳定,错误率非常低。
大部分批次使用了内存或执行器模型,说明模型非常关键。
内存模型总体准确,执行器模型在大占用情况 precision 较低。
BTBS解决了超大规模构建的资源限制问题,提高了效率。
Copy

请以markdown格式输出这篇论文的思维导图

YH
好的,这里是用Markdown格式输出的该论文思维导图:

markdown

Copy code

# Google代码库庞大

# 单次变更影响大量构建目标 

# 一次构建太多目标容易OOM或超时

## BTBS

- 接收构建目标
- 分组目标
- 排序目标
- 分批目标
    - 内存模型
    - 执行器模型  
- 创建构建
- 失败重试

## 内存模型

- 预测内存使用

## 执行器模型

- 预测执行器使用
以#作为一级标题,##作为二级标题,分别表示了论文的主要点和子点。

-BTBS部分用-表示了其工作流程,内存模型和执行器模型用子标题表示。

通过层级的标题显示了论文的知识框架。首先是问题背景,然后介绍BTBS解决方案,最后提到两个关键模型。以Markdown格式表达了该论文的核心思路。
好的,这里详细解析该论文中内存预测模型的实现:

1. 数据收集

- Bazel记录每次构建的内存峰值和Full GC后的内存峰值。

- 如果有Full GC,则后者作为预测标签;否则前者作为标签。

- 构建参数和目标作为预测特征。

2. 特征工程

- 使用互信息法等评估特征重要性,选择对预测影响较大的特征。

- 将目标路径等分类特征离散为one-hot向量。

- 通过特征交叉等方式扩充特征。

3. 模型训练

- 训练回归模型以预测内存峰值。

- 使用L1正则化,对目标相关特征正则化系数设为无穷大。

- 使目标相关特征权重非负,以保证单调性。

- 每日使用近17天数据重新训练。

4. 模型服务

- 内存模型部署为RPC服务,二分查找时即时查询。

- 同时部署使用近期数据和长期数据训练的两个模型,取最大值。

- 处理RPC错误的fallback逻辑。

通过上述流程,内存模型可以相对准确地预测构建内存使用,指导分批过程,降低内存错误。

